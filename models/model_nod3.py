import torch
import torch.nn as nn
import torch.nn.functional as F

#agregando scores
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv3d(1, 128, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm3d(128)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm3d(128)
        self.relu2 = nn.ReLU()
        self.conv3 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm3d(128)
        self.relu3 = nn.ReLU()
        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)   
        self.conv4 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm3d(128)
        self.relu4 = nn.ReLU()
        self.conv5 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn5 = nn.BatchNorm3d(128)
        self.relu5 = nn.ReLU()
        self.conv6 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn6 = nn.BatchNorm3d(128)
        self.relu6 = nn.ReLU()
        self.conv7 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn7 = nn.BatchNorm3d(128)
        self.relu7 = nn.ReLU()
        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)
        self.conv8 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn8 = nn.BatchNorm3d(128)
        self.relu8 = nn.ReLU()
        self.conv9 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn9 = nn.BatchNorm3d(128)
        self.relu9 = nn.ReLU()
        self.conv10 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn10 = nn.BatchNorm3d(128)
        self.relu10 = nn.ReLU()
        self.conv11 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn11 = nn.BatchNorm3d(128)
        self.relu11 = nn.ReLU()
        self.conv12 = nn.Conv3d(128, 128, kernel_size=3, padding=1)
        self.bn12 = nn.BatchNorm3d(128)
        self.relu12 = nn.ReLU()         
        self.conv13 = nn.Conv3d(128, 128, kernel_size=6, padding=0)
        self.bn13 = nn.BatchNorm3d(128)
        self.relu13 = nn.ReLU()
        #self.fc1 = nn.Linear(128*6*6*6, 128)
        #self.relu13 = nn.ReLU()
        self.fc2 = nn.Linear(128, 2)
        self.softmax = nn.Softmax()
        
    def forward(self, x):
        out = self.relu1(self.bn1(self.conv1(x)))
        out = self.relu2(self.bn2(self.conv2(out)))
        out = self.pool1(self.relu3(self.bn3(self.conv3(out))))
        out = self.relu4(self.bn4(self.conv4(out)))
        out = self.relu5(self.bn5(self.conv5(out)))
        out = self.relu6(self.bn6(self.conv6(out)))
        out = self.pool2(self.relu7(self.bn7(self.conv7(out))))
        out = self.relu8(self.bn8(self.conv8(out)))
        out = self.relu9(self.bn9(self.conv9(out)))
        out = self.relu10(self.bn10(self.conv10(out)))
        out = self.relu11(self.bn11(self.conv11(out)))
        out = self.relu12(self.bn12(self.conv12(out)))
        out = self.relu13(self.bn13(self.conv13(out)))
        out = self.fc2(out.view(-1, 128))
        #out = self.fc2(self.fc1((out.view(-1, 128)))
        out = self.softmax(out) 
        return out

